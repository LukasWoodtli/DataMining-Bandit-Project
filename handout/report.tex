\documentclass[a4paper, 11pt]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage[pdftex]{hyperref}
\usepackage{listings}

%\lstset{
%breaklines=true,
%breakatwhitespace=true
%}
\lstset{basicstyle=\small}

% Lengths and indenting
\setlength{\textwidth}{16.5cm}
\setlength{\marginparwidth}{1.5cm}
\setlength{\parindent}{0cm}
\setlength{\parskip}{0.15cm}
\setlength{\textheight}{22cm}
\setlength{\oddsidemargin}{0cm}
\setlength{\evensidemargin}{\oddsidemargin}
\setlength{\topmargin}{0cm}
\setlength{\headheight}{0cm}
\setlength{\headsep}{0cm}

\setcounter{secnumdepth}{1}

\renewcommand{\familydefault}{\sfdefault}

\title{Data Mining: Learning from Large Data Sets - Fall Semester 2015}
\author{mwurm@student.ethz.ch\\ merkim@student.ethz.ch\\ lwoodtli@student.ethz.ch\\}
\date{\today}

\begin{document}
\maketitle

\section*{Extracting Representative Elements} 

\subsection{Problem Description}
The goal of this project was to learn a policy that explores and exploits available user choices for yahoo news articles. This was done in order to learn user preferences and recommend other relevant articles to the users.

\subsection{Approach of the Team}
In this project the team, that the first approach to follow was to implement the LinUCB algorithm that is described in the lecture slides. This version includes the user features into its evaluation. (This should not be confused with the version in the original paper [Li et al WWW'10],  which uses the articles instead.)

The easier $\epsilon$-greedy approach was declined from the beginning, since it was assumed that it will never be good enough to reach the desired result.
The algorithm was then implemented iteratively until it worked properly.

Performance was an important element to consider. While the first naive implementation did not run through because of an timeout occured, the program ran through fast enough after several optimizations. It was necessary to export as much code as possible to the update function instead of executing it each step. Especially calculating the matrix inverse has a signifcant impact on the performance.

After the algorithm was optimized to run in a reasonable time it needed to be optimized to provide a good result. The main parameter for otimizing the prediction result was $\alpha$. The ideal value for the parameter was evaluated mainly by trial.


TODO.... abschnitt Ã¼ber alpha verbessern!




\subsection{Environment}
In contrast to the previous projects, the code for this one was not executed within a map-reduce environment. There was only a single policy file, in which the heuristic to predict the user click behavior had to be implemented.\\
As training data, log data of yahoo is available. Since we train our model on real log data, it is not possible to get a feedback for each prediction. The reason for this is that yahoo might have displayed another article. Like this we could have gotten a feedback for the other prediction but not for the current one.


\subsection{Posslible Improvements}
A possible improvement would be the implementation of the Hybrid LinUCB algorithm. It has the same runtime complexity as the standard LinUCB algorithm, but it would make it possible to exloit the information of the user and article features together.

\subsection{Conclusion}
This project shows that sometimes a proper tweaking of the parameter variables might be equaly helpfully like using an overall more complex algorithm. It reveals that proposals can be made, using a rather easy algorithm.
\end{document} 
